{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6442425,
          "sourceType": "datasetVersion",
          "datasetId": 3718381
        }
      ],
      "dockerImageVersionId": 30558,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " <h1><b><i>Sentiment Analysis on Restaurant Reviews</i></b></h1>"
      ],
      "metadata": {
        "id": "5TNwJ1n6kikp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT 1: Provide a 1-2 paragraph **high level** overview of the purpose (what is going on AND why) of this Notebook, including the various steps as indicated by the following titles (some additional detail can be provided by subtitles within the notebook, but this description should remain 'high level'):\n",
        "*   Exploratory Data Analysis\n",
        "*   Model Training\n",
        "*   Predictions\n",
        "*   Overall Accuracy\n",
        "\n",
        "NOTE: You may find this TEXT 1 easier to write AT THE END, after having completely run the Notebook and completed the rest of the assignment."
      ],
      "metadata": {
        "id": "efmvMyS6U88O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Importing the libraries"
      ],
      "metadata": {
        "id": "9Vx632BsmdHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library Loading"
      ],
      "metadata": {
        "id": "8DLGXa-bpNu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing essential Libraries\n",
        "\n",
        "# NumPy is used for numerical computations and working with arrays.\n",
        "import numpy as np\n",
        "\n",
        "# Pandas is used for data manipulation and analysis.\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "0d_SOFx7o_DH",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:33.911939Z",
          "iopub.execute_input": "2023-09-15T15:34:33.9123Z",
          "iopub.status.idle": "2023-09-15T15:34:34.327869Z",
          "shell.execute_reply.started": "2023-09-15T15:34:33.912273Z",
          "shell.execute_reply": "2023-09-15T15:34:34.32686Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "OXgGljDWpkAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Data Loading</b></h2>  Be sure you have uploaded the Restaurant_Reviews.csv data file to the Files area of Colab."
      ],
      "metadata": {
        "id": "Gxz22Xd2ppjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(r'Restaurant_Reviews.csv')"
      ],
      "metadata": {
        "id": "KPfyziXhpouQ",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.329142Z",
          "iopub.execute_input": "2023-09-15T15:34:34.329558Z",
          "iopub.status.idle": "2023-09-15T15:34:34.346813Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.329531Z",
          "shell.execute_reply": "2023-09-15T15:34:34.345749Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Descriptive Data Analysis</b></h2>"
      ],
      "metadata": {
        "id": "49auMdOXqRba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "xyDHu2zJp7uH",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.348449Z",
          "iopub.execute_input": "2023-09-15T15:34:34.34879Z",
          "iopub.status.idle": "2023-09-15T15:34:34.357108Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.348761Z",
          "shell.execute_reply": "2023-09-15T15:34:34.356003Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "H_6JC43_qb7l",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.361359Z",
          "iopub.execute_input": "2023-09-15T15:34:34.361731Z",
          "iopub.status.idle": "2023-09-15T15:34:34.37128Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.361702Z",
          "shell.execute_reply": "2023-09-15T15:34:34.370123Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "dN7oCkPSqTNm",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.373091Z",
          "iopub.execute_input": "2023-09-15T15:34:34.373492Z",
          "iopub.status.idle": "2023-09-15T15:34:34.390046Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.373447Z",
          "shell.execute_reply": "2023-09-15T15:34:34.388648Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "mZSvsehtqWMe",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.392426Z",
          "iopub.execute_input": "2023-09-15T15:34:34.392848Z",
          "iopub.status.idle": "2023-09-15T15:34:34.403967Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.392811Z",
          "shell.execute_reply": "2023-09-15T15:34:34.402716Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(5)"
      ],
      "metadata": {
        "id": "cZRXqKjbqYXe",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.405364Z",
          "iopub.execute_input": "2023-09-15T15:34:34.405884Z",
          "iopub.status.idle": "2023-09-15T15:34:34.4226Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.405846Z",
          "shell.execute_reply": "2023-09-15T15:34:34.421461Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "jtl5LyCIqaI6",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.423799Z",
          "iopub.execute_input": "2023-09-15T15:34:34.425226Z",
          "iopub.status.idle": "2023-09-15T15:34:34.440188Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.425147Z",
          "shell.execute_reply": "2023-09-15T15:34:34.438816Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Liked'].value_counts()"
      ],
      "metadata": {
        "id": "SpM1KtAgD0JQ",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.442249Z",
          "iopub.execute_input": "2023-09-15T15:34:34.443279Z",
          "iopub.status.idle": "2023-09-15T15:34:34.457766Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.443228Z",
          "shell.execute_reply": "2023-09-15T15:34:34.456605Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "bnIdVzH3qdkQ",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.459226Z",
          "iopub.execute_input": "2023-09-15T15:34:34.46008Z",
          "iopub.status.idle": "2023-09-15T15:34:34.480545Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.460046Z",
          "shell.execute_reply": "2023-09-15T15:34:34.479476Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "av9B5OL6qi9P",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.481843Z",
          "iopub.execute_input": "2023-09-15T15:34:34.482263Z",
          "iopub.status.idle": "2023-09-15T15:34:34.495699Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.482222Z",
          "shell.execute_reply": "2023-09-15T15:34:34.493913Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "O5G9KgedqlhU",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.501413Z",
          "iopub.execute_input": "2023-09-15T15:34:34.501999Z",
          "iopub.status.idle": "2023-09-15T15:34:34.517872Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.501951Z",
          "shell.execute_reply": "2023-09-15T15:34:34.51682Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "fig = make_subplots(rows=1, cols=2,specs=[[{'type':'xy'}, {'type':'domain'}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Bar(\n",
        "        x=df['Liked'].value_counts().index,\n",
        "        y= df['Liked'].value_counts().values,\n",
        "         marker=dict(color=['#6B816C','#91B092']), showlegend=False,\n",
        "           text=df['Liked'].value_counts().values, textposition='auto', textfont=dict(size=18)\n",
        "        ),\n",
        "    row=1,col=1\n",
        "    )\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Pie(\n",
        "        labels=df['Liked'].value_counts().index,\n",
        "        values=df['Liked'].value_counts().values,\n",
        "         marker=dict(colors=['#6B816C','#91B092']), textfont=dict(size=18),\n",
        "         pull=[0.01,0.01]\n",
        "        ),\n",
        "    row=1,col=2\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig.update_layout(title='<b>Distribution of the target<b>',\n",
        "                 title_font={'size':25},\n",
        "                 paper_bgcolor='#E0E1CD',\n",
        "                 plot_bgcolor='#E0E1CD',\n",
        "                 showlegend=True)\n",
        "\n",
        "fig.update_yaxes(showgrid=False)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "TrY71lgjiFK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT 2: In 2-3 sentences, based on the results of the Descriptive Data Analysis, provide a description of the dataset, filling in context that you can gather from the data itself, since you have not been given a data dictionary or description of the dataset.  Include 'technical' aspects of the dataset: how many rows, columns, datatypes, etc.  What does the 'Distribution of the target' visualization tell you about the 'balance' of the data?"
      ],
      "metadata": {
        "id": "ox5merMfmW4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**\n"
      ],
      "metadata": {
        "id": "INw2eXk-ENWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Length'] = df['Review'].apply(len)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "_cAdXGw4ERgr",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.524963Z",
          "iopub.execute_input": "2023-09-15T15:34:34.525712Z",
          "iopub.status.idle": "2023-09-15T15:34:34.540376Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.525671Z",
          "shell.execute_reply": "2023-09-15T15:34:34.539308Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT 3: What has been accomplished in the previous cell and why?"
      ],
      "metadata": {
        "id": "95DThYn6oGh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**\n"
      ],
      "metadata": {
        "id": "aG5VcbNiq4sG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Importing essential NLP libraries</b></h2>"
      ],
      "metadata": {
        "id": "3IkLNhE-q-9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comment 1: <What are stopwords and why are they used in NLP?>\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "# Download NLTK stopwords data\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n"
      ],
      "metadata": {
        "id": "S8p30YrFq-VI",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:34.542061Z",
          "iopub.execute_input": "2023-09-15T15:34:34.542774Z",
          "iopub.status.idle": "2023-09-15T15:34:35.520482Z",
          "shell.execute_reply.started": "2023-09-15T15:34:34.542736Z",
          "shell.execute_reply": "2023-09-15T15:34:35.519082Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(stopwords.words('english')))"
      ],
      "metadata": {
        "id": "1QAFUTmXErvx",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:35.521843Z",
          "iopub.execute_input": "2023-09-15T15:34:35.522238Z",
          "iopub.status.idle": "2023-09-15T15:34:35.531558Z",
          "shell.execute_reply.started": "2023-09-15T15:34:35.522209Z",
          "shell.execute_reply": "2023-09-15T15:34:35.529982Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.remove('not')\n",
        "'not' in stop_words"
      ],
      "metadata": {
        "id": "H8vU37vndIsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT 3: In the previous cell, we searched for the word 'not' in stopwords and removed it, if it was in the list.  The final line of code, *'not' in stop_words*, returns as 'False', which is a confirmation that 'not' isn’t (or is no longer) in the list.    \n",
        "\n",
        "Consider your response to Comment 1, what are stopwords and why are they used in NLP?  \n",
        "\n",
        "**Why might it be important to remove 'not' from the stopwords list?  HINT: have a look at the code and output in the next cell.**"
      ],
      "metadata": {
        "id": "t5i_pU7rkSch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original :',df.Review.iloc[1])\n",
        "print('processed with not removing negation :',' '.join([word for word in df.Review.iloc[1].split() if word not in stop_words]))"
      ],
      "metadata": {
        "id": "pLMBI-L0epjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning the Reviews and Creating a Corpus\n",
        "# This cell is the perfect example of how several important ML tasks can be included in a single cell and run in 1.7 seconds with a single click.\n",
        "# It's important to know what our code does in each cell, each line.\n",
        "\n",
        "# Comment 2: <What is the purpose of 'cleaning the reviews'?>\n",
        "# Comment 3: <What does the line corpus = [] do, what is its purpose?>\n",
        "\n",
        "corpus = []\n",
        "\n",
        "# Loop through the first 1000 reviews (adjust the range as needed) in the DataFrame 'df'.\n",
        "for i in range(0, 1000):\n",
        "\n",
        "    # Comment 4: Step 1: <What does the following line do (what AND why)?>\n",
        "    review = re.sub(pattern='[^a-zA-Z]', repl=' ', string=df['Review'][i])\n",
        "\n",
        "    # Comment 5: Step 2: <What does the following line do (what AND why)?>\n",
        "    review = review.lower()\n",
        "\n",
        "    # Comment 6: Step 3: Tokenization, <What does the following line do (what AND why)?>\n",
        "    review_words = review.split()\n",
        "\n",
        "    # Comment 7: Step 4: Removing Stop Words, <What does the following line do (what AND why)?>\n",
        "    review_words = [word for word in review_words if word not in stop_words]\n",
        "\n",
        "    # Comment 8: Step 5: Stemming, <What does the following line do (what AND why)?>\n",
        "    ps = PorterStemmer()\n",
        "    review = [ps.stem(word) for word in review_words]\n",
        "\n",
        "    # Comment 9: Step 6: Rejoining Tokens, <What does the following line do (what AND why)?>\n",
        "    review = ' '.join(review)\n",
        "\n",
        "    # Comment 10: Step 7: Append to Corpus, <What does the following line do (what AND why)?>\n",
        "    corpus.append(review)\n",
        "\n",
        "# Comment 11: After running this code, 'corpus' will contain <finish this phrase, what is the end result to the dataset, of the previous 7 steps>\n"
      ],
      "metadata": {
        "id": "ze6rpzI6q07r",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:35.533177Z",
          "iopub.execute_input": "2023-09-15T15:34:35.5335Z",
          "iopub.status.idle": "2023-09-15T15:34:37.519576Z",
          "shell.execute_reply.started": "2023-09-15T15:34:35.533473Z",
          "shell.execute_reply": "2023-09-15T15:34:37.518114Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:20]"
      ],
      "metadata": {
        "id": "6kP0YsqMspjX",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:37.521216Z",
          "iopub.execute_input": "2023-09-15T15:34:37.521617Z",
          "iopub.status.idle": "2023-09-15T15:34:37.529148Z",
          "shell.execute_reply.started": "2023-09-15T15:34:37.521586Z",
          "shell.execute_reply": "2023-09-15T15:34:37.528016Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Cloud"
      ],
      "metadata": {
        "id": "NHDjBxhkFQz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import library\n",
        "# positive review\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "word_cloud = df.loc[df['Liked'] == 1,:]\n",
        "text = ' '.join([text for text in word_cloud['Review']])\n",
        "# Generate a WordCloud object\n",
        "wordcloud = WordCloud(width=800, height=400,background_color='white').generate(text)\n",
        "# Display the word cloud using matplotlib\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9_nW-qitFPO1",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:37.530367Z",
          "iopub.execute_input": "2023-09-15T15:34:37.530687Z",
          "iopub.status.idle": "2023-09-15T15:34:38.752038Z",
          "shell.execute_reply.started": "2023-09-15T15:34:37.53066Z",
          "shell.execute_reply": "2023-09-15T15:34:38.750727Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code Modification 1: Copy and paste the code from the previous cell.\n",
        "#Change two parameters to change the Word Cloud to depict negative reviews with a background in some color of your choice, other than white.\n",
        "#Include the Code and a snip or cut and paste of your output in the Assignment Responses document.\n",
        "#Modify comments to reflect the new image\n",
        "\n"
      ],
      "metadata": {
        "id": "fWTIeuh3q6B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Bag of Words Model\n",
        "# For more detail on Bag of Words: https://builtin.com/machine-learning/bag-of-words\n",
        "\n",
        "# Import the CountVectorizer class from scikit-learn, which is used to convert text data into numerical features.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize a CountVectorizer with a specified maximum number of features (max_features).\n",
        "# The 'max_features' parameter controls the number of most frequent words to keep in the vocabulary.\n",
        "# Adjust this value based on your specific requirements.\n",
        "cv = CountVectorizer(max_features=1500)\n",
        "\n",
        "# Apply the CountVectorizer to the 'corpus' to transform the text data into a numerical representation.\n",
        "# The 'fit_transform' method converts the text into a sparse matrix where rows represent reviews and columns represent words.\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "\n",
        "# 'X' now contains the BoW representation of the text data.\n",
        "\n",
        "# Extract the target variable 'y' from the DataFrame 'df'.\n",
        "# Assuming the target variable is located in the second column (index 1) of the DataFrame.\n",
        "y = df.iloc[:, 1].values\n",
        "\n",
        "# 'y' now contains the labels or target values corresponding to each review.\n",
        "\n",
        "# The resulting 'X' and 'y' can be used to train machine learning models for tasks such as sentiment analysis or text classification.\n"
      ],
      "metadata": {
        "id": "Lyvou8Edsu7A",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:38.7538Z",
          "iopub.execute_input": "2023-09-15T15:34:38.754399Z",
          "iopub.status.idle": "2023-09-15T15:34:38.783514Z",
          "shell.execute_reply.started": "2023-09-15T15:34:38.75437Z",
          "shell.execute_reply": "2023-09-15T15:34:38.782727Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Data Splitting</b></h2>"
      ],
      "metadata": {
        "id": "s1ogipp7tc2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the Dataset into Training and Testing Sets\n",
        "\n",
        "# Comment 12: In this code, we split the dataset into training and testing sets to <finish this sentence, what is the purpose of splitting the dataset into two sets?>\n",
        "\n",
        "# Import the 'train_test_split' function from scikit-learn, which is used for splitting datasets.\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the feature matrix 'X' and the target variable 'y' into training and testing sets.\n",
        "# The 'test_size' parameter specifies the proportion of the dataset to include in the test split.\n",
        "# Here, 20% of the data is reserved for testing (test_size=0.20).\n",
        "# The 'random_state' parameter ensures reproducibility by fixing the random seed for the split.\n",
        "# This means that the same split will be obtained every time you run the code with the same random_state value.\n",
        "\n",
        "############################################################################################\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "\n",
        "# 'X_train' and 'y_train' contain the features and labels for the training set, respectively.\n",
        "# 'X_test' and 'y_test' contain the features and labels for the testing set, respectively.\n",
        "\n",
        "# The dataset is typically divided into a training set (used to train the model) and a testing set (used to evaluate the model's performance).\n",
        "# The proportions used in this split can be adjusted based on the specific requirements of your analysis.\n",
        "\n",
        "# In this example, the dataset contains 1000 samples, and 80% (800 samples) are used for training,\n",
        "# while 20% (200 samples) are used for testing. These proportions can be modified as needed.\n"
      ],
      "metadata": {
        "id": "YL3wPLoVtXjK",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:38.784559Z",
          "iopub.execute_input": "2023-09-15T15:34:38.785591Z",
          "iopub.status.idle": "2023-09-15T15:34:38.803013Z",
          "shell.execute_reply.started": "2023-09-15T15:34:38.785559Z",
          "shell.execute_reply": "2023-09-15T15:34:38.802042Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "OnDG1p4nuGzE",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:34:38.804436Z",
          "iopub.execute_input": "2023-09-15T15:34:38.804803Z",
          "iopub.status.idle": "2023-09-15T15:34:38.81497Z",
          "shell.execute_reply.started": "2023-09-15T15:34:38.804773Z",
          "shell.execute_reply": "2023-09-15T15:34:38.814241Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "dNOA2SRUu2kV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT 4: This notebook runs several algorithms on the dataset.  In layman's terms, explain the difference between machine learning for classification vs machine learning for prediction.  Can both approaches be applied to this problem?  Or is this problem more suited to one approach?"
      ],
      "metadata": {
        "id": "Y69fVV5EuPp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, GradientBoostingClassifier,\n",
        "    AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier,\n",
        ")\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.linear_model import (\n",
        "    LogisticRegression, SGDClassifier, RidgeClassifier,\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Define a dictionary of models with their names as keys and model instances as values\n",
        "models = {\n",
        "    'MultinomialNB': MultinomialNB(),\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "    'BaggingClassifier': BaggingClassifier(),\n",
        "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
        "    'SVC': SVC(),\n",
        "    'LinearSVC': LinearSVC(),\n",
        "    'NuSVC': NuSVC(),\n",
        "    'LogisticRegression': LogisticRegression(),\n",
        "    'SGDClassifier': SGDClassifier(),\n",
        "    'RidgeClassifier': RidgeClassifier(),\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "\n",
        "}\n",
        "\n",
        "# Create an empty dictionary to store model accuracies\n",
        "# ... Your code up to the loop ...\n",
        "\n",
        "# Create an empty dictionary to store model accuracies and their differences\n",
        "model_accuracies = {}\n",
        "model_accuracies_diff = {}\n",
        "\n",
        "# Specify the number of folds (k)\n",
        "num_folds = 11\n",
        "\n",
        "# Initialize a KFold cross-validator\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Loop through each model and train/evaluate it with k-fold cross-validation\n",
        "for model_name, model in models.items():\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Calculate the average training and testing accuracy across all folds\n",
        "    average_train_accuracy = np.mean(train_accuracies)\n",
        "    average_test_accuracy = np.mean(test_accuracies)\n",
        "\n",
        "    # Calculate the difference between training and testing accuracy\n",
        "    accuracy_diff = abs(average_train_accuracy - average_test_accuracy)\n",
        "\n",
        "    # Print training and testing accuracy for the model\n",
        "    print(f\"{model_name}: Training Accuracy={average_train_accuracy * 100:.2f}%, Testing Accuracy={average_test_accuracy * 100:.2f}%, Accuracy Difference={accuracy_diff * 100:.2f}%\")\n",
        "    print(\"=\"*149)\n",
        "\n",
        "    # Store the average testing accuracy and the difference in accuracies in the model_accuracies and model_accuracies_diff dictionaries\n",
        "    model_accuracies[model_name] = average_test_accuracy\n",
        "    model_accuracies_diff[model_name] = accuracy_diff\n",
        "\n",
        "# Sort the models based on the absolute difference between training and testing accuracy\n",
        "sorted_models = sorted(model_accuracies_diff.items(), key=lambda x: x[1])\n",
        "print()\n",
        "# Print the best models in ascending order of accuracy difference\n",
        "print(\"︻\"*149)\n",
        "print()\n",
        "print(\"Best Models (Closest Training and Testing Accuracy):\")\n",
        "print()\n",
        "print(\"︻\"*149)\n",
        "print()\n",
        "for model_name, accuracy_diff in sorted_models:\n",
        "    print(f\"{model_name}: Accuracy Difference={accuracy_diff * 100:.2f}%\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "# Print the model with the smallest accuracy difference (best model)\n",
        "best_model_name = sorted_models[0][0]\n",
        "print(f\"The Best Model is: {best_model_name}\")"
      ],
      "metadata": {
        "id": "OppaLE59GWD6",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:38:32.042099Z",
          "iopub.execute_input": "2023-09-15T15:38:32.04351Z",
          "iopub.status.idle": "2023-09-15T15:40:16.860128Z",
          "shell.execute_reply.started": "2023-09-15T15:38:32.043456Z",
          "shell.execute_reply": "2023-09-15T15:40:16.858956Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT 5: Your non-data scientist boss (or client) asks you \"What's the difference between training accuracy and testing accuracy and what's the significance of the 'Accuracy Difference'?  Why don't we just choose the highest training accuracy?\" Please respond to the two/three questions in layman's terms, but be aware that you must provide some background otherwise the specific answers to the questions may not suffice.  Begin by explaining the machine learning notion of training data vs testing data. Additional hint: at some point you should mention (and define) 'overfitting', how it is caused, how these metrics might help identify it and why overfitting should be avoided.\n"
      ],
      "metadata": {
        "id": "VnTuFi97vtHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the Test set results\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "5CvreTVrvPyo",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:05.58874Z",
          "iopub.execute_input": "2023-09-15T15:41:05.589245Z",
          "iopub.status.idle": "2023-09-15T15:41:05.598984Z",
          "shell.execute_reply.started": "2023-09-15T15:41:05.589208Z",
          "shell.execute_reply": "2023-09-15T15:41:05.597711Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Load your data (X and y) here\n",
        "\n",
        "# Create an AdaBoostClassifier instance\n",
        "ada_boost_classifier = AdaBoostClassifier()\n",
        "\n",
        "# Specify the number of folds (k)\n",
        "num_folds = 11\n",
        "\n",
        "# Initialize a KFold cross-validator\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store metrics for each fold\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "confusion_matrices = []\n",
        "classification_reports = []\n",
        "\n",
        "# Loop through each fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the AdaBoostClassifier on the training data\n",
        "    ada_boost_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the training data\n",
        "    y_train_pred = ada_boost_classifier.predict(X_train)\n",
        "\n",
        "    # Calculate training accuracy for the fold\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_test_pred = ada_boost_classifier.predict(X_test)\n",
        "\n",
        "    # Calculate testing accuracy for the fold\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # Calculate precision, recall, and F1-score for the fold\n",
        "    precision = precision_score(y_test, y_test_pred)\n",
        "    recall = recall_score(y_test, y_test_pred)\n",
        "    f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    # Calculate and store the confusion matrix for the fold\n",
        "    confusion = confusion_matrix(y_test, y_test_pred)\n",
        "    confusion_matrices.append(confusion)\n",
        "\n",
        "    # Generate and store the classification report for the fold\n",
        "    classification = classification_report(y_test, y_test_pred)\n",
        "    classification_reports.append(classification)\n",
        "\n",
        "# Calculate the average training and testing accuracies\n",
        "average_train_accuracy = np.mean(train_accuracies)\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "average_accuracy_difference = np.mean(train_accuracy - test_accuracies)\n",
        "# Calculate the average precision, recall, and F1-score\n",
        "average_precision = np.mean(precision_scores)\n",
        "average_recall = np.mean(recall_scores)\n",
        "average_f1 = np.mean(f1_scores)\n",
        "\n",
        "# Print the results\n",
        "print(\"AdaBoostClassifier Results:\")\n",
        "print(\"-\"*150)\n",
        "print(f\"Average Training Accuracy: {average_train_accuracy * 100:.2f}%\")\n",
        "print(\"-\"*150)\n",
        "print(f\"Average Testing Accuracy: {average_test_accuracy * 100:.2f}%\")\n",
        "print(\"-\"*150)\n",
        "print(f\"Average Accuracies Difference: {average_accuracy_difference * 100:.2f}%\")\n",
        "print(\"-\"*150)\n",
        "print(f\"Average Precision: {average_precision:.2f}\")\n",
        "print(\"-\"*150)\n",
        "print(f\"Average Recall: {average_recall:.2f}\")\n",
        "print(\"-\"*150)\n",
        "print(f\"Average F1-score: {average_f1:.2f}\")\n",
        "print(\"-\"*150)"
      ],
      "metadata": {
        "id": "P_v4JXaIvYyx",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:08.134468Z",
          "iopub.execute_input": "2023-09-15T15:41:08.134853Z",
          "iopub.status.idle": "2023-09-15T15:41:17.489417Z",
          "shell.execute_reply.started": "2023-09-15T15:41:08.134825Z",
          "shell.execute_reply": "2023-09-15T15:41:17.488206Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and store the confusion matrix for the fold\n",
        "confusion = confusion_matrix(y_test, y_test_pred)\n",
        "confusion_matrices.append(confusion)\n",
        "\n",
        "# Print the confusion matrix for the current fold\n",
        "print(f\"Confusion Matrix - Fold {len(confusion_matrices)}:\\n{confusion}\")\n"
      ],
      "metadata": {
        "id": "i8P96f_GvjX1",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:20.257335Z",
          "iopub.execute_input": "2023-09-15T15:41:20.25808Z",
          "iopub.status.idle": "2023-09-15T15:41:20.267113Z",
          "shell.execute_reply.started": "2023-09-15T15:41:20.258043Z",
          "shell.execute_reply": "2023-09-15T15:41:20.265719Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Create a heatmap to visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6rOqA418wtdq",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:22.221088Z",
          "iopub.execute_input": "2023-09-15T15:41:22.221464Z",
          "iopub.status.idle": "2023-09-15T15:41:22.427968Z",
          "shell.execute_reply.started": "2023-09-15T15:41:22.221436Z",
          "shell.execute_reply": "2023-09-15T15:41:22.426856Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT 6: In layman's terms, explain the significance of each cell of the Confusion Matrix.  HINT: Your explanation should detail the results within the context of 'true' and 'predicted' axes and labels."
      ],
      "metadata": {
        "id": "576jPwEqy_7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and store the classification report for the fold\n",
        "classification = classification_report(y_test, y_test_pred)\n",
        "classification_reports.append(classification)\n",
        "\n",
        "# Print the classification report for the current fold\n",
        "print(f\"Classification Report - Fold {len(classification_reports)}:\\n{classification}\")\n"
      ],
      "metadata": {
        "id": "AScuAYC9wfpg",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:25.458947Z",
          "iopub.execute_input": "2023-09-15T15:41:25.459509Z",
          "iopub.status.idle": "2023-09-15T15:41:25.476923Z",
          "shell.execute_reply.started": "2023-09-15T15:41:25.45947Z",
          "shell.execute_reply": "2023-09-15T15:41:25.475287Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>HyperParameterTune the NaiveBayesClassifier</b></h2>"
      ],
      "metadata": {
        "id": "N8AbeQwgw92T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Using Stratified Kfold</h2>"
      ],
      "metadata": {
        "id": "LwfSuD4jx2eG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Load your data (X and y) here\n",
        "\n",
        "# Create an AdaBoostClassifier instance\n",
        "ada_boost_classifier = AdaBoostClassifier()\n",
        "\n",
        "# Specify the number of folds (k) and use StratifiedKFold\n",
        "num_folds = 5\n",
        "stratified_kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store metrics for each fold\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "# Loop through each fold\n",
        "for train_index, test_index in stratified_kf.split(X, y):  # Notice the addition of 'y'\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the AdaBoostClassifier on the training data\n",
        "    ada_boost_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the training data\n",
        "    y_train_pred = ada_boost_classifier.predict(X_train)\n",
        "\n",
        "    # Calculate training accuracy for the fold\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_test_pred = ada_boost_classifier.predict(X_test)\n",
        "\n",
        "    # Calculate testing accuracy for the fold\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "# Calculate the average training and testing accuracies\n",
        "average_train_accuracy = np.mean(train_accuracies)\n",
        "average_test_accuracy = np.mean(test_accuracies)\n",
        "average_accuracy_difference = np.mean(train_accuracy - test_accuracies)\n",
        "# Print the results\n",
        "print(\"AdaBoostClassifier Results with Stratified k-fold Cross-Validation:\")\n",
        "print(\"=\"*149)\n",
        "print(f\"Average Training Accuracy: {average_train_accuracy * 100:.2f}%\")\n",
        "print(\"=\"*149)\n",
        "print(f\"Average Testing Accuracy: {average_test_accuracy * 100:.2f}%\")\n",
        "print(\"=\"*149)\n",
        "print(f\"Average Accuracy Difference: {average_accuracy_difference * 100:.2f}%\")\n",
        "print(\"=\"*149)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a bar plot\n",
        "categories = ['Training Accuracy', 'Testing Accuracy', 'Accuracy Difference']\n",
        "values = [average_train_accuracy, average_test_accuracy, average_accuracy_difference]\n",
        "plt.bar(categories, values, color=['blue', 'green', 'red'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Training and Testing Accuracies')\n",
        "plt.ylim(0, 1.0)  # Set the y-axis limits between 0 and 1\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_dGFjuKMwi7z",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:29.59994Z",
          "iopub.execute_input": "2023-09-15T15:41:29.600722Z",
          "iopub.status.idle": "2023-09-15T15:41:33.51934Z",
          "shell.execute_reply.started": "2023-09-15T15:41:29.60068Z",
          "shell.execute_reply": "2023-09-15T15:41:33.518073Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Predictions**"
      ],
      "metadata": {
        "id": "JmyktYt-yYb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "def predict_sentiment(sample_review, ada_boost_classifier, cv):\n",
        "    # Preprocess the sample review\n",
        "    sample_review = re.sub(pattern='[^a-zA-Z]', repl=' ', string=sample_review)\n",
        "    sample_review = sample_review.lower()\n",
        "    sample_review_words = sample_review.split()\n",
        "    sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]\n",
        "    ps = PorterStemmer()\n",
        "    final_review = [ps.stem(word) for word in sample_review_words]\n",
        "    final_review = ' '.join(final_review)\n",
        "\n",
        "    # Transform the preprocessed review using the CountVectorizer (cv)\n",
        "    temp = cv.transform([final_review]).toarray()\n",
        "\n",
        "    # Use the pre-trained classifier to predict sentiment\n",
        "    sentiment = ada_boost_classifier.predict(temp)\n",
        "\n",
        "    return sentiment[0]  # Return the predicted sentiment (assuming it's a single value)\n"
      ],
      "metadata": {
        "id": "d9mtgrQgyW8f",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:40.081224Z",
          "iopub.execute_input": "2023-09-15T15:41:40.081596Z",
          "iopub.status.idle": "2023-09-15T15:41:40.0901Z",
          "shell.execute_reply.started": "2023-09-15T15:41:40.081568Z",
          "shell.execute_reply": "2023-09-15T15:41:40.089102Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample reviews as strings\n",
        "reviews = [\n",
        "    'The food is really bad.',\n",
        "    'I love their delicious dishes!',\n",
        "    'Terrible experience. Avoid this place.',\n",
        "    'The service was excellent.',\n",
        "    'Worst place ever, but nice food'\n",
        "]\n",
        "\n",
        "for review in reviews:\n",
        "    sentiment = predict_sentiment(review, ada_boost_classifier, cv)\n",
        "    if sentiment:\n",
        "        sentiment_label = 'POSITIVE'\n",
        "    else:\n",
        "        sentiment_label = 'NEGATIVE'\n",
        "\n",
        "    print(f\"Review: '{review}'\")\n",
        "    print(f\"Sentiment: {sentiment_label}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "Pt4-eCNLyrDG",
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:42.125309Z",
          "iopub.execute_input": "2023-09-15T15:41:42.126237Z",
          "iopub.status.idle": "2023-09-15T15:41:42.192596Z",
          "shell.execute_reply.started": "2023-09-15T15:41:42.126204Z",
          "shell.execute_reply": "2023-09-15T15:41:42.191124Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall Accuracy"
      ],
      "metadata": {
        "id": "lgk2QX8eRlIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AdaBoostClassifier Results with Stratified k-fold Cross-Validation:\")\n",
        "print(\"=\"*149)\n",
        "print(f\"Average Training Accuracy: {average_train_accuracy * 100:.2f}%\")\n",
        "print(\"=\"*149)\n",
        "print(f\"Average Testing Accuracy: {average_test_accuracy * 100:.2f}%\")\n",
        "print(\"=\"*149)\n",
        "print(f\"Average Accuracy Difference: {average_accuracy_difference * 100:.2f}%\")\n",
        "print(\"=\"*149)\n",
        "\n",
        "\n",
        "\n",
        "# Create a bar plot\n",
        "categories = ['Training Accuracy', 'Testing Accuracy', 'Accuracy Difference']\n",
        "values = [average_train_accuracy, average_test_accuracy, average_accuracy_difference]\n",
        "plt.bar(categories, values, color=['blue', 'green', 'red'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Training and Testing Accuracies')\n",
        "plt.ylim(0, 1.0)  # Set the y-axis limits between 0 and 1\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-15T15:41:49.760564Z",
          "iopub.execute_input": "2023-09-15T15:41:49.760947Z",
          "iopub.status.idle": "2023-09-15T15:41:50.019127Z",
          "shell.execute_reply.started": "2023-09-15T15:41:49.76092Z",
          "shell.execute_reply": "2023-09-15T15:41:50.017896Z"
        },
        "trusted": true,
        "id": "yfhtJ2erRlIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment Analysis with VADER (Valence Aware Dictionary and sEntiment Reasoner)"
      ],
      "metadata": {
        "id": "2fg7fb_psEOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VADER** is a pre-built sentiment analysis tool commonly used (NLP). It is designed to analyze text data and determine the sentiment polarity of the text, i.e., whether the text expresses positive, negative, or neutral sentiment.\n",
        "\n",
        "**VADER** is particularly useful for sentiment analysis of social media text, short texts, and informal language, as it is specifically tuned for such contexts.\n",
        "\n",
        "**Compound Score :** VADER provides a compound score that represents the overall sentiment of the text, taking into account both positive and negative language. The compound score can help in quantifying sentiment intensity.\n",
        "\n",
        "For more information on VADER:\n",
        "\n",
        "*   https://www.codeproject.com/Articles/5269445/Using-Pre-trained-VADER-Models-for-NLTK-Sentiment\n",
        "*   https://www.codeproject.com/Articles/5269447/Pros-and-Cons-of-NLTK-Sentiment-Analysis-with-VADE\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Itay2IbPqoC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "\n",
        "def sent_analysis(corpus):\n",
        "    '''\n",
        "    input : The text\n",
        "    output : The sentiment of the text\n",
        "    '''\n",
        "    sentiment = vader.polarity_scores(corpus)\n",
        "    compound_score = sentiment['compound']\n",
        "\n",
        "    if compound_score > 0 :\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n"
      ],
      "metadata": {
        "id": "EnwtQGhsmpsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['vader_sent'] = df['Review'].apply(lambda x : sent_analysis(x))\n"
      ],
      "metadata": {
        "id": "IcZEisvKnV_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "cm_names = ['True Negative' ,'False Positive','False Negative' ,'True Positive']\n",
        "cm=confusion_matrix(df['Liked'],df['vader_sent'])\n",
        "value_count = [ value  for value in cm.flatten()]\n",
        "presentage = [value for value in  cm.flatten()/ np.sum(cm)  ]\n",
        "all_labels = [f'{v1}  \\n{v2}\\n {v3*100:.2f} %' for v1 ,v2 ,v3 in zip(cm_names ,value_count,presentage )]\n",
        "all_labels = np.asarray(all_labels).reshape(2,2)\n",
        "sns.heatmap(cm,annot=all_labels,cmap='Reds',\n",
        "                linewidth=3,fmt='',\n",
        "                xticklabels=['Negative','Positive'],\n",
        "                yticklabels=['Negative','Positive']\n",
        "               )\n",
        "\n",
        "\n",
        "plt.title(' CM of all data ')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KHRiZswJnZXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT 7: a) Offer any final comments on the Predictions, Overall Accuracy and CM of the final models. b) What was the purpose of introducing 'sample reviews as strings'?  Were the results as you expected?  c) Any observations regarding the VADER model?"
      ],
      "metadata": {
        "id": "PDSnVHf8zvxV"
      }
    }
  ]
}